{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfaa984f-596c-4385-8c88-1d042ff921e4",
   "metadata": {},
   "source": [
    "# Data Streaming Pipline\n",
    "using:\n",
    "- Spark Streaming (3.1.2)\n",
    "- Pyspark (3.1.2)\n",
    "- Kafka (Confluent cloud)\n",
    "- ElasticSearch (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22c49e-0a70-4dfe-96b9-4275f45cc16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Elasticsearch\n",
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde79856-378e-45e6-b361-3d5fea5523c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.19) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, FloatType, MapType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b4d53-156f-451f-abae-220bd295032b",
   "metadata": {},
   "source": [
    "### Creating Elatsicsearc index using Command line \n",
    "\n",
    "curl -X PUT \"http://10.0.3.36:9200/events\" -H 'Content-Type: application/json' -d'\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"eventType\": { \"type\": \"keyword\" },\n",
    "      \"customerId\": { \"type\": \"keyword\" },\n",
    "      \"productId\": { \"type\": \"keyword\" },,\n",
    "      \"timestamp\": { \"type\": \"keyword\"},,\n",
    "      \"metadata\": {  \"type\": \"keyword\"},\n",
    "        \"type\": \"object\",\n",
    "        \"enabled\": true\",\n",
    "      },\"enabled\": true\n",
    "      \"quantity\": { \"type\": \"integer\" },\n",
    "      \"totalAmount\": { \"type\": \"float\" },\n",
    "      \"paymentMethod\": { \"type\": \"keyword\" },\n",
    "      \"recommendedProductId\": { \"type\": \"keyword\" }\n",
    "    } \"recommendedProductId\": { \"type\": \"keyword\" }\n",
    "  } }\n",
    "}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c20bd9-de99-45b0-9b81-0cd5c8413555",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test inserting to Elasticsearch index with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3b684c0-448e-4fd3-b2ca-53c4ef9d4365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itversity/.local/lib/python3.6/site-packages/ipykernel_launcher.py:39: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(\n",
    "    [{'scheme': 'http', 'host': '192.168.33.139', 'port': 9200}]\n",
    ")\n",
    "\n",
    "# Define sample data\n",
    "sample_data = [\n",
    "    {\n",
    "        \"eventType\": \"purchase\",\n",
    "        \"customerId\": \"C123\",\n",
    "        \"productId\": \"P456\",\n",
    "        \"timestamp\": \"2024-07-27T12:34:56.789Z\",\n",
    "        \"metadata\": {\n",
    "            \"category\": \"electronics\",\n",
    "            \"source\": \"website\"\n",
    "        },\n",
    "        \"quantity\": 2,\n",
    "        \"totalAmount\": 199.99,\n",
    "        \"paymentMethod\": \"credit_card\",\n",
    "        \"recommendedProductId\": \"P789\"\n",
    "    },\n",
    "    {\n",
    "        \"eventType\": \"view\",\n",
    "        \"customerId\": \"C124\",\n",
    "        \"productId\": \"P457\",\n",
    "        \"timestamp\": \"2024-07-27T13:45:56.789Z\",\n",
    "        \"metadata\": {},\n",
    "        \"quantity\": 1,\n",
    "        \"totalAmount\": 0.0,\n",
    "        \"paymentMethod\": \"none\",\n",
    "        \"recommendedProductId\": \"P790\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Index the sample data\n",
    "for i, doc in enumerate(sample_data):\n",
    "    es.index(index='events', id=i+1, document=doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bd317e-cd28-4131-98cc-3824ea7f7271",
   "metadata": {},
   "source": [
    "## Test reading data from Elasticsearch index with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f6663-f3af-468b-a0e1-1958c71729be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(\n",
    "    hosts=[\n",
    "        {\n",
    "            'host': '192.168.33.139',\n",
    "            'port': 9200,\n",
    "            'scheme': 'http'  # or 'https' if you are using SSL\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define a search query to retrieve all documents\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the search query\n",
    "response = es.search(index='events', body=query)\n",
    "\n",
    "# Print the retrieved documents\n",
    "for hit in response['hits']['hits']:\n",
    "    print(hit['_source'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a62e2-d370-453b-a966-e03093d4407f",
   "metadata": {},
   "source": [
    "## Test inserting to Elasticsearch index with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fedb7c3-834b-44c7-82d5-21668d20cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestToElasticsearch\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2,org.elasticsearch:elasticsearch-spark-30_2.12:7.15.2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType() \\\n",
    "    .add(\"eventType\", StringType()) \\\n",
    "    .add(\"customerId\", StringType()) \\\n",
    "    .add(\"productId\", StringType()) \\\n",
    "    .add(\"timestamp\", StringType()) \\\n",
    "    .add(\"metadata\", MapType(StringType(), StringType())) \\\n",
    "    .add(\"quantity\", IntegerType()) \\\n",
    "    .add(\"totalAmount\", FloatType()) \\\n",
    "    .add(\"paymentMethod\", StringType())\n",
    "\n",
    "# Create test data DataFrame\n",
    "test_data = spark.createDataFrame([{\n",
    "    'eventType': 'purchase',\n",
    "    'customerId': '12345',\n",
    "    'productId': '67890',\n",
    "    'timestamp': '2024-07-27T11:44:45',\n",
    "    'metadata': {'category': 'Books', 'source': 'Advertisement'},\n",
    "    'quantity': 1,\n",
    "    'totalAmount': 15.75,\n",
    "    'paymentMethod': 'Credit Card'\n",
    "}], schema)\n",
    "\n",
    "# Elasticsearch configuration\n",
    "es_write_conf = {\n",
    "    \"es.nodes\": \"192.168.33.139\",\n",
    "    \"es.port\": \"9200\",\n",
    "    \"es.index.auto.create\": \"true\"\n",
    "}\n",
    "\n",
    "# Write data to Elasticsearch\n",
    "test_data.write \\\n",
    "    .format(\"org.elasticsearch.spark.sql\") \\\n",
    "    .options(**es_write_conf) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save(\"events\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f0efb-c35f-49a2-b5c3-20e2868fb027",
   "metadata": {},
   "source": [
    "## Reading data from Confluent Kafka Cloud and inserting it to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6eab90f-f0c4-4301-aacf-a1d63606ff8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d199d22ae945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Await termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mes_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark3/python/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark3/python/pyspark/context.py\u001b[0m in \u001b[0;36msignal_handler\u001b[0;34m(signal, frame)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msignal_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancelAllJobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;31m# see http://stackoverflow.com/questions/23206787/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "outputDir = \"hdfs://localhost:9000/user/itversity/stream_output\"\n",
    "checkpointDir = \"hdfs://localhost:9000/user/itversity/stream_checkpoint\"\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaToElasticsearch\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2,org.elasticsearch:elasticsearch-spark-30_2.12:7.15.2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define schema for the incoming JSON data\n",
    "schema = StructType() \\\n",
    "    .add(\"eventType\", StringType()) \\\n",
    "    .add(\"customerId\", StringType()) \\\n",
    "    .add(\"productId\", StringType()) \\\n",
    "    .add(\"timestamp\", StringType()) \\\n",
    "    .add(\"metadata\", MapType(StringType(), StringType())) \\\n",
    "    .add(\"quantity\", IntegerType()) \\\n",
    "    .add(\"totalAmount\", FloatType()) \\\n",
    "    .add(\"paymentMethod\", StringType()) \\\n",
    "    .add(\"recommendedProductId\", StringType(), True)  # Optional field\n",
    "\n",
    "# Kafka connection details\n",
    "bootstrap_servers = \"pkc-921jm.us-east-2.aws.confluent.cloud:9092\"\n",
    "kafka_topic = \"demo_topic\"  # Your Kafka topic name\n",
    "kafka_username = \"6UX76KJG3N363E2H\"\n",
    "kafka_password = \"dWAj0CPM50FkljxdqW1z/1yH2am/FQdb7MicZ01vr/F0Zu8WRFx6Fx0fDpXWrt06\"\n",
    "\n",
    "# Read data from Kafka topic as a streaming DataFrame\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", bootstrap_servers) \\\n",
    "    .option(\"subscribe\", kafka_topic) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"kafka.security.protocol\", \"SASL_SSL\") \\\n",
    "    .option(\"kafka.sasl.mechanism\", \"PLAIN\") \\\n",
    "    .option(\"kafka.sasl.jaas.config\",\n",
    "            f'org.apache.kafka.common.security.plain.PlainLoginModule required username=\"{kafka_username}\" password=\"{kafka_password}\";') \\\n",
    "    .load()\n",
    "\n",
    "# Parse the JSON data\n",
    "json_df = df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "            .select(from_json(\"value\", schema).alias(\"data\")) \\\n",
    "            .select(\"data.*\")\n",
    "\n",
    "\n",
    "# Elasticsearch configuration\n",
    "es_write_conf = {\n",
    "    \"es.nodes\": \"192.168.33.139\",\n",
    "    \"es.port\": \"9200\",\n",
    "    \"es.resource\": \"events/_doc\",\n",
    "    \"es.nodes.wan.only\": \"true\",\n",
    "    \"es.write.operation\": \"index\",\n",
    "    \"es.index.auto.create\": \"true\"\n",
    "}\n",
    "\n",
    "\n",
    "# Write to Elasticsearch\n",
    "es_query = json_df.writeStream \\\n",
    "    .format(\"org.elasticsearch.spark.sql\") \\\n",
    "    .options(**es_write_conf) \\\n",
    "    .option(\"checkpointLocation\", checkpointDir) \\\n",
    "    .start()\n",
    "\n",
    "# Await termination\n",
    "es_query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd66a2d-ba1d-4847-87fd-9150c585ac51",
   "metadata": {},
   "source": [
    "## Test count inserted records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41cc6edc-9317-4f20-af12-b87fb3b1c8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"count\":58,\"_shards\":{\"total\":1,\"successful\":1,\"skipped\":0,\"failed\":0}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://192.168.33.139:9200/events/_count\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370ef53-6da5-4603-a944-ff7e3f1b8f9b",
   "metadata": {},
   "source": [
    "## Test Filter Recordrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5820e7c6-4284-45cc-b4c8-18f6a69281f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 23, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 13, 'relation': 'eq'}, 'max_score': 1.4748477, 'hits': [{'_index': 'events', '_type': '_doc', '_id': 'c8GD9JABPle8ZzxyG1-O', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '94706', 'productId': '8327', 'timestamp': '2024-07-27T17:05:11', 'metadata': {}, 'recommendedProductId': '2335'}}, {'_index': 'events', '_type': '_doc', '_id': 'dcGD9JABPle8ZzxyG1-O', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '40976', 'productId': '4564', 'timestamp': '2024-07-27T17:05:13', 'metadata': {}, 'recommendedProductId': '6915'}}, {'_index': 'events', '_type': '_doc', '_id': 'Z8GC9JABPle8Zzxy01_9', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '14487', 'productId': '6253', 'timestamp': '2024-07-27T17:04:54', 'metadata': {}, 'recommendedProductId': '4391'}}, {'_index': 'events', '_type': '_doc', '_id': 'acGC9JABPle8Zzxy7l8L', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '23389', 'productId': '7294', 'timestamp': '2024-07-27T17:04:33', 'metadata': {}, 'recommendedProductId': '4065'}}, {'_index': 'events', '_type': '_doc', '_id': 'asGC9JABPle8Zzxy7l8L', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '74029', 'productId': '2919', 'timestamp': '2024-07-27T17:04:36', 'metadata': {}, 'recommendedProductId': '2037'}}, {'_index': 'events', '_type': '_doc', '_id': 'WMGC9JABPle8ZzxypF-B', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '71524', 'productId': '4378', 'timestamp': '2024-07-27T17:04:30', 'metadata': {}, 'recommendedProductId': '1496'}}, {'_index': 'events', '_type': '_doc', '_id': 'dsGD9JABPle8ZzxyHF9K', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '40653', 'productId': '8148', 'timestamp': '2024-07-27T17:05:07', 'metadata': {}, 'recommendedProductId': '7803'}}, {'_index': 'events', '_type': '_doc', '_id': 'd8GD9JABPle8ZzxyHF9K', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '58341', 'productId': '3687', 'timestamp': '2024-07-27T17:05:13', 'metadata': {}, 'recommendedProductId': '7635'}}, {'_index': 'events', '_type': '_doc', '_id': 'WsGC9JABPle8Zzxyyl-5', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '95506', 'productId': '4291', 'timestamp': '2024-07-27T17:04:32', 'metadata': {}, 'recommendedProductId': '7274'}}, {'_index': 'events', '_type': '_doc', '_id': 'gsGD9JABPle8ZzxyVl-i', '_score': 1.4748477, '_source': {'eventType': 'recommendationClick', 'customerId': '26721', 'productId': '8143', 'timestamp': '2024-07-27T17:05:02', 'metadata': {}, 'recommendedProductId': '5059'}}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itversity/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n"
     ]
    }
   ],
   "source": [
    "# Create a client instance with scheme, host, and port\n",
    "es = Elasticsearch([{'scheme': 'http', 'host': '192.168.33.139', 'port': 9200}])  # Adjust scheme, host, and port as needed\n",
    "\n",
    "# Define the search query\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [\n",
    "                            { \"match\": { \"eventType\": \"recommendationClick\" }}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the search query\n",
    "response = es.search(index=\"events\", body=query)\n",
    "\n",
    "# Print the search results\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f43b11-1c3a-45be-a973-032379b121a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e49606-f0b5-417a-98a9-3d39b385d9a7",
   "metadata": {},
   "source": [
    "## Run With Spark Submit\n",
    "\n",
    "`spark-submit --master local[1] --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2,org.elasticsearch:elasticsearch-spark-30_2.12:7.15.2 data-pipeline/src/main/java/com/example/sparkToELastic.py\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5333fa3-b0ab-476d-bc78-b1ad6040a267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
